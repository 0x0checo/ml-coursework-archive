{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoB2nEhTGEFBbl7XvPChgU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0x0checo/NLP/blob/main/Huggingface_Transformer(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eqA9gQkWJCB7"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Day 3**\n",
        "\n",
        "*Fine tuning a pretrained model*"
      ],
      "metadata": {
        "id": "AwO8ZYa1JM5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QWu-n2vLJW4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset = raw_datasets['train']\n",
        "raw_train_dataset[0]"
      ],
      "metadata": {
        "id": "bOaHtF79J38J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset.features"
      ],
      "metadata": {
        "id": "5kiVpt4NKJy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess a dataset**"
      ],
      "metadata": {
        "id": "aZfRmllqKmNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenized_sentences_1 = tokenizer(raw_datasets['train']['sentence1'])\n",
        "tokenized_sentences_2 = tokenizer(raw_datasets['train']['sentence2'])\n"
      ],
      "metadata": {
        "id": "ENidZXBPKpvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "token_type_ids, in this example, this is what tells the model which part of the input is the first sentence and which is the second sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "fmNhsC5ANP1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
        "inputs"
      ],
      "metadata": {
        "id": "jFK_NkyKNK69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenizer(\n",
        "    raw_datasets[\"train\"][\"sentence1\"],\n",
        "    raw_datasets[\"train\"][\"sentence2\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        ")"
      ],
      "metadata": {
        "id": "7Us2jzRnPhxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™ç§æ–¹æ³•æ•ˆæœå¾ˆå¥½ï¼Œä½†å®ƒçš„ç¼ºç‚¹æ˜¯è¿”å›ä¸€ä¸ªå­—å…¸ï¼ˆåŒ…å«æˆ‘ä»¬çš„é”®ï¼š`input_ids`ã€`attention_mask` å’Œ `token_type_ids`ï¼Œä»¥åŠå€¼ï¼Œè¿™äº›å€¼æ˜¯åˆ—è¡¨çš„åˆ—è¡¨ï¼‰ã€‚å¦‚æœåœ¨æ ‡è®°åŒ–è¿‡ç¨‹ä¸­æ²¡æœ‰è¶³å¤Ÿçš„å†…å­˜æ¥å­˜å‚¨æ•´ä¸ªæ•°æ®é›†ï¼Œå®ƒä¹Ÿåªä¼šåœ¨å†…å­˜è¶³å¤Ÿçš„æƒ…å†µä¸‹å·¥ä½œï¼ˆè€ŒğŸ¤— Datasetsåº“ä¸­çš„æ•°æ®é›†æ˜¯å­˜å‚¨åœ¨ç£ç›˜ä¸Šçš„ Apache Arrow æ–‡ä»¶ï¼Œå› æ­¤åªä¼šå°†æ‚¨è¦æ±‚åŠ è½½åˆ°å†…å­˜ä¸­çš„æ ·æœ¬ä¿ç•™åœ¨å†…å­˜ä¸­ï¼‰ã€‚\n",
        "\n",
        "ä¸ºäº†å°†æ•°æ®ä¿æŒä¸ºæ•°æ®é›†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `Dataset.map()` æ–¹æ³•ã€‚è¿™è¿˜å¯ä»¥ä¸ºæˆ‘ä»¬æä¾›ä¸€äº›é¢å¤–çš„çµæ´»æ€§ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦æ‰§è¡Œæ›´å¤šçš„é¢„å¤„ç†æ“ä½œï¼Œè€Œä¸ä»…ä»…æ˜¯æ ‡è®°åŒ–ã€‚`map()` æ–¹æ³•é€šè¿‡å¯¹æ•°æ®é›†ä¸­çš„æ¯ä¸ªå…ƒç´ åº”ç”¨ä¸€ä¸ªå‡½æ•°æ¥å·¥ä½œï¼Œå› æ­¤è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ ‡è®°åŒ–æˆ‘ä»¬çš„è¾“å…¥ï¼š"
      ],
      "metadata": {
        "id": "_kRAR1NYQmI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
      ],
      "metadata": {
        "id": "Kp4tHiaUQp5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™ä¸ªå‡½æ•°æ¥å—ä¸€ä¸ªå­—å…¸ï¼ˆåƒæˆ‘ä»¬æ•°æ®é›†çš„æ¡ç›®ï¼‰ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…å« `input_ids`ã€`attention_mask` å’Œ `token_type_ids` çš„æ–°å­—å…¸ã€‚è¯·æ³¨æ„ï¼Œå¦‚æœç¤ºä¾‹å­—å…¸åŒ…å«å¤šä¸ªæ ·æœ¬ï¼ˆæ¯ä¸ªé”®æ˜¯ä¸€ä¸ªå¥å­çš„åˆ—è¡¨ï¼‰ï¼Œè¿™ä¸ªå‡½æ•°ä»ç„¶æœ‰æ•ˆï¼Œå› ä¸ºå¦‚å‰æ‰€è¿°ï¼Œæ ‡è®°å™¨å¯ä»¥å¤„ç†å¤šä¸ªå¥å­å¯¹çš„åˆ—è¡¨ã€‚è¿™å°†å…è®¸æˆ‘ä»¬åœ¨è°ƒç”¨ `map()` æ—¶ä½¿ç”¨ `batched=True` é€‰é¡¹ï¼Œè¿™å°†å¤§å¤§åŠ å¿«æ ‡è®°åŒ–çš„é€Ÿåº¦ã€‚æ ‡è®°å™¨ç”±ğŸ¤— Tokenizersåº“ä¸­çš„ Rust ç¼–å†™çš„æ ‡è®°å™¨æ”¯æŒï¼Œè¿™ç§æ ‡è®°å™¨éå¸¸å¿«ï¼Œä½†å‰ææ˜¯æˆ‘ä»¬ä¸€æ¬¡æ€§æä¾›å¤§é‡è¾“å…¥ã€‚\n",
        "\n",
        "è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æš‚æ—¶åœ¨æ ‡è®°åŒ–å‡½æ•°ä¸­æ²¡æœ‰ä½¿ç”¨ `padding` å‚æ•°ã€‚è¿™æ˜¯å› ä¸ºå°†æ‰€æœ‰æ ·æœ¬å¡«å……åˆ°æœ€å¤§é•¿åº¦å¹¶ä¸æ˜¯é«˜æ•ˆçš„ï¼šæœ€å¥½åœ¨æ„å»ºæ‰¹æ¬¡æ—¶è¿›è¡Œå¡«å……ï¼Œå› ä¸ºé‚£æ—¶æˆ‘ä»¬åªéœ€è¦å¡«å……åˆ°è¯¥æ‰¹æ¬¡çš„æœ€å¤§é•¿åº¦ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ•°æ®é›†çš„æœ€å¤§é•¿åº¦ã€‚å½“è¾“å…¥çš„é•¿åº¦å·®å¼‚å¾ˆå¤§æ—¶ï¼Œè¿™å¯ä»¥èŠ‚çœå¤§é‡æ—¶é—´å’Œè®¡ç®—èµ„æºï¼\n",
        "\n",
        "ä¸‹é¢æ˜¯æˆ‘ä»¬å¦‚ä½•ä¸€æ¬¡æ€§å°†æ ‡è®°åŒ–å‡½æ•°åº”ç”¨äºæ‰€æœ‰æ•°æ®é›†ã€‚æˆ‘ä»¬åœ¨è°ƒç”¨ `map` æ—¶ä½¿ç”¨ `batched=True`ï¼Œè¿™æ ·å‡½æ•°å°±ä¼šä¸€æ¬¡æ€§åº”ç”¨äºæ•°æ®é›†çš„å¤šä¸ªå…ƒç´ ï¼Œè€Œä¸æ˜¯åˆ†åˆ«åº”ç”¨äºæ¯ä¸ªå…ƒç´ ã€‚è¿™å¯ä»¥åŠ é€Ÿé¢„å¤„ç†è¿‡ç¨‹ã€‚"
      ],
      "metadata": {
        "id": "oV6RQCtxTIPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XyOTrxrpTJ4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è´Ÿè´£å°†æ ·æœ¬æ”¾å…¥æ‰¹æ¬¡ä¸­çš„å‡½æ•°å«åš **collate function**ï¼ˆåˆå¹¶å‡½æ•°ï¼‰ã€‚è¿™æ˜¯æ‚¨åœ¨æ„å»º `DataLoader` æ—¶å¯ä»¥ä¼ é€’çš„ä¸€ä¸ªå‚æ•°ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œåˆå¹¶å‡½æ•°ä¼šå°†æ ·æœ¬è½¬æ¢ä¸º PyTorch å¼ é‡å¹¶å°†å®ƒä»¬æ‹¼æ¥åœ¨ä¸€èµ·ï¼ˆå¦‚æœæ‚¨çš„å…ƒç´ æ˜¯åˆ—è¡¨ã€å…ƒç»„æˆ–å­—å…¸ï¼Œå®ƒä¼šé€’å½’åœ°è¿›è¡Œæ‹¼æ¥ï¼‰ã€‚åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œè¿™ç§æ–¹æ³•ä¸å¯è¡Œï¼Œå› ä¸ºæˆ‘ä»¬çš„è¾“å…¥å¤§å°å¹¶ä¸ç›¸åŒã€‚æˆ‘ä»¬æ•…æ„æ¨è¿Ÿäº†å¡«å……æ“ä½œï¼Œç›´åˆ°æ¯ä¸ªæ‰¹æ¬¡éœ€è¦æ—¶æ‰åº”ç”¨å¡«å……ï¼Œä»è€Œé¿å…å‡ºç°å¡«å……è¿‡å¤šå¯¼è‡´è¾“å…¥è¿‡é•¿çš„æƒ…å†µã€‚è¿™å°†å¤§å¤§åŠ é€Ÿè®­ç»ƒï¼Œä½†è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨åœ¨ TPU ä¸Šè®­ç»ƒï¼Œå®ƒå¯èƒ½ä¼šå¼•å‘é—®é¢˜â€”â€”TPU æ›´å€¾å‘äºå›ºå®šå½¢çŠ¶çš„è¾“å…¥ï¼Œå³ä½¿è¿™éœ€è¦é¢å¤–çš„å¡«å……ã€‚\n",
        "\n",
        "ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¿…é¡»å®šä¹‰ä¸€ä¸ªåˆå¹¶å‡½æ•°ï¼Œè¯¥å‡½æ•°ä¼šå¯¹æˆ‘ä»¬æƒ³è¦æ‰¹å¤„ç†åœ¨ä¸€èµ·çš„æ•°æ®é›†ä¸­çš„é¡¹ç›®åº”ç”¨æ­£ç¡®æ•°é‡çš„å¡«å……ã€‚å¹¸è¿çš„æ˜¯ï¼ŒğŸ¤— Transformers åº“é€šè¿‡ `DataCollatorWithPadding` æä¾›äº†è¿™æ ·çš„ä¸€ä¸ªå‡½æ•°ã€‚åœ¨å®ä¾‹åŒ–æ—¶ï¼Œå®ƒä¼šæ¥æ”¶ä¸€ä¸ªæ ‡è®°å™¨ï¼ˆç”¨æ¥ç¡®å®šä½¿ç”¨å“ªç§å¡«å……ç¬¦å·ï¼Œä»¥åŠæ¨¡å‹æ˜¯å¦æœŸæœ›å°†å¡«å……æ”¾åœ¨è¾“å…¥çš„å·¦ä¾§æˆ–å³ä¾§ï¼‰ï¼Œå¹¶ä¼šæ‰§è¡Œæ‚¨æ‰€éœ€çš„æ‰€æœ‰æ“ä½œï¼š"
      ],
      "metadata": {
        "id": "MCqJskWeYOUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "tPMuk26yYmZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ª `DataCollatorWithPadding` å¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™ `data_collator` å˜é‡ã€‚å…·ä½“è§£é‡Šå¦‚ä¸‹ï¼š\n",
        "\n",
        "- **`DataCollatorWithPadding`**ï¼šè¿™æ˜¯ ğŸ¤— Transformers åº“æä¾›çš„ä¸€ä¸ªæ•°æ®åˆå¹¶å™¨ï¼ˆcollatorï¼‰ï¼Œç”¨äºåœ¨æ‰¹å¤„ç†æ•°æ®æ—¶æ‰§è¡Œå¡«å……ï¼ˆpaddingï¼‰æ“ä½œã€‚å®ƒä¼šè‡ªåŠ¨å°†è¾“å…¥æ ·æœ¬å¡«å……åˆ°æ‰¹æ¬¡å†…çš„æœ€å¤§é•¿åº¦ã€‚è¿™ä¸ªåˆå¹¶å™¨é€šå¸¸ç”¨äºå¤„ç†è¾“å…¥é•¿åº¦ä¸ä¸€è‡´çš„æƒ…å†µï¼Œç¡®ä¿æ‰€æœ‰æ ·æœ¬åœ¨æ‰¹å¤„ç†æ—¶æœ‰ç›¸åŒçš„é•¿åº¦ã€‚\n",
        "\n",
        "- **`tokenizer=tokenizer`**ï¼šè¿™é‡Œå°†å·²ç»å®šä¹‰çš„ `tokenizer` ä¼ é€’ç»™ `DataCollatorWithPadding`ã€‚`tokenizer` ç”¨äºç¡®å®šå“ªäº›å¡«å……ç¬¦å·ï¼ˆpadding tokenï¼‰åº”è¯¥è¢«ä½¿ç”¨ï¼Œæ­¤å¤–ï¼Œå®ƒè¿˜ä¼šå‘Šè¯‰ `DataCollatorWithPadding` æ¨¡å‹æ˜¯å¦éœ€è¦å°†å¡«å……ç¬¦å·æ”¾åœ¨è¾“å…¥çš„å·¦ä¾§æˆ–å³ä¾§ã€‚\n",
        "\n",
        "ç®€è€Œè¨€ä¹‹ï¼Œè¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯è®¾ç½®ä¸€ä¸ªå¡«å……åˆå¹¶å™¨ï¼Œå®ƒä¼šåœ¨æ¯ä¸ªæ‰¹æ¬¡çš„æ ·æœ¬è¢«æ‰“åŒ…æ—¶æ ¹æ® `tokenizer` è‡ªåŠ¨å¡«å……æ ·æœ¬ï¼Œä»¥ä¿è¯æ¯ä¸ªæ‰¹æ¬¡å†…çš„æ ·æœ¬å…·æœ‰ç›¸åŒçš„é•¿åº¦ã€‚"
      ],
      "metadata": {
        "id": "euw2XxcYwsRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
        "[len(x) for x in samples[\"input_ids\"]]"
      ],
      "metadata": {
        "id": "iswmyQI6YwHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator(samples)\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "id": "Md0t_g0mZuIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning a model with the Trainer API**"
      ],
      "metadata": {
        "id": "zKEskYrUtl2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨æˆ‘ä»¬å®šä¹‰ `Trainer` ä¹‹å‰ï¼Œç¬¬ä¸€æ­¥æ˜¯å®šä¹‰ä¸€ä¸ª `TrainingArguments` ç±»ï¼Œå®ƒå°†åŒ…å« `Trainer` åœ¨è®­ç»ƒå’Œè¯„ä¼°è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ‰€æœ‰è¶…å‚æ•°ã€‚æ‚¨éœ€è¦æä¾›çš„å”¯ä¸€å‚æ•°æ˜¯ä¸€ä¸ªç›®å½•ï¼Œç”¨äºä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹ä»¥åŠä¸­é—´çš„æ£€æŸ¥ç‚¹ã€‚å¯¹äºå…¶ä»–å‚æ•°ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨é»˜è®¤å€¼ï¼Œè¿™äº›é»˜è®¤å€¼åº”è¯¥é€‚ç”¨äºåŸºæœ¬çš„å¾®è°ƒä»»åŠ¡ã€‚"
      ],
      "metadata": {
        "id": "qKz-q5r-udYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")"
      ],
      "metadata": {
        "id": "PiQTFJs6tqHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "id": "ZRX-PzOGvHhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "QtWtVRZVvw_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fine-tune the model on our dataset, we just have to call the train() method of our Trainer:"
      ],
      "metadata": {
        "id": "S32eCLh7wmSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "fkE5tc0uw-Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™å°†å¼€å§‹å¾®è°ƒï¼ˆåœ¨ GPU ä¸Šåº”è¯¥åªéœ€è¦å‡ åˆ†é’Ÿï¼‰ï¼Œå¹¶æ¯ 500 æ­¥æŠ¥å‘Šä¸€æ¬¡è®­ç»ƒæŸå¤±ã€‚ç„¶è€Œï¼Œå®ƒä¸ä¼šå‘Šè¯‰æ‚¨æ¨¡å‹çš„è¡¨ç°å¦‚ä½•ï¼ˆå¥½æˆ–åï¼‰ã€‚åŸå› å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. æˆ‘ä»¬æ²¡æœ‰å‘Šè¯‰ `Trainer` åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œè¯„ä¼°ï¼Œæœªè®¾ç½® `evaluation_strategy` ä¸º \"steps\"ï¼ˆæ¯éš” `eval_steps` æ­¥è¿›è¡Œè¯„ä¼°ï¼‰æˆ– \"epoch\"ï¼ˆåœ¨æ¯ä¸ª epoch ç»“æŸæ—¶è¿›è¡Œè¯„ä¼°ï¼‰ã€‚\n",
        "2. æˆ‘ä»¬æ²¡æœ‰ä¸º `Trainer` æä¾›ä¸€ä¸ª `compute_metrics()` å‡½æ•°æ¥åœ¨è¯„ä¼°æ—¶è®¡ç®—æŒ‡æ ‡ï¼ˆå¦åˆ™ï¼Œè¯„ä¼°åªä¼šè¾“å‡ºæŸå¤±ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªå¾ˆç›´è§‚çš„æŒ‡æ ‡ï¼‰ã€‚\n",
        "\n",
        "**è¯„ä¼°**\n",
        "è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ„å»ºä¸€ä¸ªæœ‰ç”¨çš„ `compute_metrics()` å‡½æ•°ï¼Œå¹¶åœ¨ä¸‹æ¬¡è®­ç»ƒæ—¶ä½¿ç”¨å®ƒã€‚è¿™ä¸ªå‡½æ•°å¿…é¡»æ¥å—ä¸€ä¸ª `EvalPrediction` å¯¹è±¡ï¼ˆè¿™æ˜¯ä¸€ä¸ªå…·æœ‰ `predictions` å’Œ `label_ids` å­—æ®µçš„å‘½åå…ƒç»„ï¼‰ï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå°†å­—ç¬¦ä¸²æ˜ å°„åˆ°æµ®åŠ¨æ•°å€¼ï¼ˆå­—ç¬¦ä¸²æ˜¯è¿”å›çš„æŒ‡æ ‡åç§°ï¼Œæµ®åŠ¨æ•°å€¼æ˜¯å®ƒä»¬çš„å€¼ï¼‰ã€‚ä¸ºäº†ä»æˆ‘ä»¬çš„æ¨¡å‹ä¸­è·å–ä¸€äº›é¢„æµ‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `Trainer.predict()` å‘½ä»¤ï¼š"
      ],
      "metadata": {
        "id": "dYRdERssx6Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ],
      "metadata": {
        "id": "KzitnpbcyGL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`predict()` æ–¹æ³•çš„è¾“å‡ºæ˜¯å¦ä¸€ä¸ªå‘½åå…ƒç»„ï¼ŒåŒ…å«ä¸‰ä¸ªå­—æ®µï¼š`predictions`ã€`label_ids` å’Œ `metrics`ã€‚`metrics` å­—æ®µå°†åŒ…å«ä¼ å…¥æ•°æ®é›†ä¸Šçš„æŸå¤±å€¼ï¼Œä»¥åŠä¸€äº›æ—¶é—´ç›¸å…³çš„æŒ‡æ ‡ï¼ˆé¢„æµ‹æ‰€éœ€çš„æ€»æ—¶é—´å’Œå¹³å‡æ—¶é—´ï¼‰ã€‚ä¸€æ—¦æˆ‘ä»¬å®Œæˆäº† `compute_metrics()` å‡½æ•°å¹¶å°†å…¶ä¼ é€’ç»™ `Trainer`ï¼Œè¿™ä¸ªå­—æ®µè¿˜ä¼šåŒ…å« `compute_metrics()` è¿”å›çš„æŒ‡æ ‡ã€‚\n",
        "\n",
        "å¦‚æ‚¨æ‰€è§ï¼Œ`predictions` æ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼Œå½¢çŠ¶ä¸º 408 x 2ï¼ˆ408 æ˜¯æˆ‘ä»¬ç”¨äºé¢„æµ‹çš„æ•°æ®é›†ä¸­çš„å…ƒç´ æ•°é‡ï¼‰ã€‚è¿™äº›æ˜¯æˆ‘ä»¬ä¼ é€’ç»™ `predict()` çš„æ¯ä¸ªå…ƒç´ çš„ logitsï¼ˆæ­£å¦‚åœ¨ä¸Šä¸€ç« ä¸­çœ‹åˆ°çš„ï¼Œæ‰€æœ‰ Transformer æ¨¡å‹éƒ½ä¼šè¿”å› logitsï¼‰ã€‚ä¸ºäº†å°†å®ƒä»¬è½¬æ¢ä¸ºæˆ‘ä»¬å¯ä»¥ä¸æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒçš„é¢„æµ‹ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç¬¬äºŒä¸ªè½´ä¸Šå–æœ€å¤§å€¼çš„ç´¢å¼•ã€‚"
      ],
      "metadata": {
        "id": "3uHYLYbuyje0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "w1EJ3KYAyl4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç°åœ¨æˆ‘ä»¬å¯ä»¥å°†è¿™äº›é¢„æµ‹å€¼ï¼ˆ`preds`ï¼‰ä¸æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒã€‚ä¸ºäº†æ„å»ºæˆ‘ä»¬çš„ `compute_metric()` å‡½æ•°ï¼Œæˆ‘ä»¬å°†ä¾èµ–äº ğŸ¤— Evaluate åº“ä¸­çš„æŒ‡æ ‡ã€‚æˆ‘ä»¬å¯ä»¥åƒåŠ è½½æ•°æ®é›†ä¸€æ ·è½»æ¾åŠ è½½ä¸ MRPC æ•°æ®é›†ç›¸å…³çš„æŒ‡æ ‡ï¼Œè¿™æ¬¡ä½¿ç”¨ `evaluate.load()` å‡½æ•°ã€‚è¿”å›çš„å¯¹è±¡å…·æœ‰ä¸€ä¸ª `compute()` æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥è¿›è¡ŒæŒ‡æ ‡è®¡ç®—ï¼š"
      ],
      "metadata": {
        "id": "IexIBF84ze7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ],
      "metadata": {
        "id": "KEvFgaRJzleh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "8xQXNBfg0OEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ª `compute_metrics` å‡½æ•°ï¼Œç”¨äºè®¡ç®—æ¨¡å‹è¯„ä¼°æ—¶çš„æ€§èƒ½æŒ‡æ ‡ã€‚ä¸‹é¢æ˜¯é€è¡Œè§£é‡Šï¼š\n",
        "\n",
        "1. **`metric = evaluate.load(\"glue\", \"mrpc\")`**ï¼š\n",
        "   - è¿™è¡Œä»£ç ä» ğŸ¤— Evaluate åº“åŠ è½½äº† MRPCï¼ˆMicrosoft Research Paraphrase Corpusï¼‰æ•°æ®é›†ç›¸å…³çš„æŒ‡æ ‡ã€‚`\"glue\"` æ˜¯ä¸€ä¸ªåŒ…å«å¤šç§ä»»åŠ¡çš„é›†åˆï¼Œ`\"mrpc\"` æ˜¯å…¶ä¸­ä¸€ä¸ªä»»åŠ¡ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°å¥å­å¯¹æ˜¯å¦ä¸ºåŒä¹‰å¥ï¼ˆå³æ–‡æœ¬å¯¹æ˜¯å¦è¡¨è¾¾ç›¸åŒçš„æ„æ€ï¼‰ã€‚è¯¥è¡Œä»£ç è¿”å›ä¸€ä¸ªå¯ä»¥è®¡ç®—æŒ‡æ ‡çš„å¯¹è±¡ã€‚\n",
        "\n",
        "2. **`logits, labels = eval_preds`**ï¼š\n",
        "   - è¿™é‡Œå°† `eval_preds`ï¼ˆä¸€ä¸ªåŒ…å«æ¨¡å‹é¢„æµ‹è¾“å‡ºå’Œæ ‡ç­¾çš„å…ƒç»„ï¼‰è§£åŒ…ä¸º `logits` å’Œ `labels`ã€‚`logits` æ˜¯æ¨¡å‹é¢„æµ‹çš„åŸå§‹è¾“å‡ºå€¼ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªæ²¡æœ‰ç»è¿‡ softmax çš„å¼ é‡ï¼‰ï¼Œ`labels` æ˜¯æ•°æ®é›†ä¸­çœŸå®çš„æ ‡ç­¾ã€‚\n",
        "\n",
        "3. **`predictions = np.argmax(logits, axis=-1)`**ï¼š\n",
        "   - ç”±äº `logits` æ˜¯æ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼Œå®ƒä»¬é€šå¸¸æ˜¯ç±»åˆ«çš„å¾—åˆ†ï¼ˆæœªå½’ä¸€åŒ–çš„æ¦‚ç‡ï¼‰ã€‚ä¸ºäº†å¾—åˆ°æœ€ç»ˆçš„é¢„æµ‹ç±»åˆ«ï¼Œä½¿ç”¨ `np.argmax` å‡½æ•°æ²¿ç€æœ€åä¸€ä¸ªç»´åº¦ï¼ˆå³ `axis=-1`ï¼‰è·å–æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œå³é€‰æ‹©å…·æœ‰æœ€é«˜å¾—åˆ†çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœã€‚\n",
        "\n",
        "4. **`return metric.compute(predictions=predictions, references=labels)`**ï¼š\n",
        "   - è¿™è¡Œä»£ç ä½¿ç”¨ `metric` å¯¹è±¡æ¥è®¡ç®—æœ€ç»ˆçš„è¯„ä¼°æŒ‡æ ‡ã€‚`metric.compute` ä¼šæ ¹æ®é¢„æµ‹å€¼ (`predictions`) å’ŒçœŸå®æ ‡ç­¾ (`references`ï¼Œå³ `labels`) è®¡ç®—å‡ºç›¸å…³çš„æŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®ç‡ã€F1å¾—åˆ†ç­‰ï¼ˆå…·ä½“å–å†³äºä»»åŠ¡ï¼‰ã€‚ç„¶åå°†è®¡ç®—å¾—åˆ°çš„ç»“æœè¿”å›ã€‚\n",
        "\n",
        "### æ€»ç»“ï¼š\n",
        "è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯ï¼š\n",
        "- åŠ è½½MRPCä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡ã€‚\n",
        "- è§£åŒ…æ¨¡å‹çš„é¢„æµ‹è¾“å‡ºï¼ˆlogitsï¼‰å’ŒçœŸå®æ ‡ç­¾ï¼ˆlabelsï¼‰ã€‚\n",
        "- å°† logits è½¬æ¢ä¸ºæœ€ç»ˆçš„é¢„æµ‹ç±»åˆ«ï¼ˆé€šè¿‡å–æœ€å¤§å€¼çš„ç´¢å¼•ï¼‰ã€‚\n",
        "- è®¡ç®—å¹¶è¿”å›è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®ç‡æˆ–F1å¾—åˆ†ç­‰ã€‚"
      ],
      "metadata": {
        "id": "cw_MIlcR1bro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final code\n",
        "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "gZf_8MYr1erU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ï¼Œ**model head**ï¼ˆæ¨¡å‹å¤´éƒ¨ï¼‰æ˜¯æŒ‡ä½äºæ¨¡å‹çš„åŸºç¡€ç½‘ç»œï¼ˆå¦‚BERTã€GPTç­‰é¢„è®­ç»ƒæ¨¡å‹ï¼‰ä¹‹åçš„éƒ¨åˆ†ï¼Œé€šå¸¸ç”¨äºç‰¹å®šä»»åŠ¡çš„è¾“å‡ºã€‚è¿™ä¸ªå¤´éƒ¨é€šå¸¸ç”±ä¸€å±‚æˆ–å¤šå±‚é¢å¤–çš„ç¥ç»ç½‘ç»œå±‚ç»„æˆï¼Œç”¨æ¥å°†æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºï¼ˆå¦‚BERTä¸­çš„éšå±‚è¡¨ç¤ºï¼‰è½¬æ¢ä¸ºç‰¹å®šä»»åŠ¡æ‰€éœ€çš„è¾“å‡ºæ ¼å¼ã€‚\n",
        "\n",
        "ä¾‹å¦‚ï¼š\n",
        "\n",
        "- **åˆ†ç±»ä»»åŠ¡**ï¼šåœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œæ¨¡å‹å¤´éƒ¨é€šå¸¸æ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆæˆ–å¤šå±‚æ„ŸçŸ¥æœºï¼ŒMLPï¼‰ï¼Œå®ƒå°†BERTæ¨¡å‹çš„è¾“å‡ºæ˜ å°„åˆ°ç±»åˆ«æ ‡ç­¾çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n",
        "- **åºåˆ—æ ‡æ³¨ä»»åŠ¡**ï¼šå¦‚å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä»»åŠ¡ï¼Œæ¨¡å‹å¤´éƒ¨å¯èƒ½åŒ…å«å¤šä¸ªåˆ†ç±»å±‚ï¼Œæ¯ä¸ªä½ç½®çš„è¾“å‡ºå¯¹åº”ä¸€ä¸ªæ ‡ç­¾ã€‚\n",
        "- **ç”Ÿæˆä»»åŠ¡**ï¼šå¯¹äºç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚æ–‡æœ¬ç”Ÿæˆï¼‰ï¼Œæ¨¡å‹å¤´éƒ¨ä¼šè´Ÿè´£ç”Ÿæˆä¸‹ä¸€ä¸ªè¯çš„é¢„æµ‹ã€‚\n",
        "\n",
        "åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œé€šå¸¸ä¼šå…ˆæœ‰ä¸€ä¸ªåŸºç¡€çš„æ¨¡å‹ï¼ˆå¦‚BERTï¼‰ï¼Œç„¶åæ ¹æ®ç›®æ ‡ä»»åŠ¡çš„ä¸åŒï¼Œä¿®æ”¹æˆ–æ›¿æ¢æ¨¡å‹çš„å¤´éƒ¨ã€‚ä¾‹å¦‚ï¼ŒBERTæ¨¡å‹é»˜è®¤ç”¨äºæ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMasked Language Modeling, MLMï¼‰ï¼Œå…¶å¤´éƒ¨è®¾è®¡ä¸ºé¢„æµ‹è¢«é®ç›–çš„å•è¯ã€‚å¦‚æœä½ ç”¨BERTè¿›è¡Œæ–‡æœ¬åˆ†ç±»æˆ–å…¶ä»–ä»»åŠ¡ï¼Œä½ å¯èƒ½éœ€è¦æ›¿æ¢è¿™ä¸ªå¤´éƒ¨ï¼Œä½¿ç”¨é€‚åˆè¯¥ä»»åŠ¡çš„è¾“å‡ºå±‚ã€‚\n",
        "\n",
        "åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå¸¸å¸¸ä¼šé‡åˆ°ä»¥ä¸‹æƒ…å†µï¼š\n",
        "- å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªå·²ç»é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆå¦‚BERTï¼‰ï¼Œè€Œè¦åšçš„æ˜¯ä¸åŒçš„ä»»åŠ¡ï¼ˆå¦‚æ–‡æœ¬åˆ†ç±»ï¼‰ï¼Œé‚£ä¹ˆåŸæ¥çš„ä»»åŠ¡å¤´éƒ¨ï¼ˆä¾‹å¦‚ç”¨äºæ©ç è¯­è¨€å»ºæ¨¡çš„å¤´éƒ¨ï¼‰ä¼šè¢«å»æ‰ï¼Œå¹¶æ›¿æ¢ä¸ºä¸€ä¸ªæ–°çš„ä»»åŠ¡å¤´éƒ¨ï¼ˆä¾‹å¦‚ç”¨äºåˆ†ç±»çš„å…¨è¿æ¥å±‚ï¼‰ã€‚"
      ],
      "metadata": {
        "id": "-B6sHbB-2o7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A full training**"
      ],
      "metadata": {
        "id": "3SBIBcZk5RRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨å®é™…ç¼–å†™è®­ç»ƒå¾ªç¯ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€äº›å¯¹è±¡ã€‚é¦–å…ˆæ˜¯æˆ‘ä»¬å°†ç”¨äºè¿­ä»£æ‰¹æ¬¡çš„æ•°æ®åŠ è½½å™¨ï¼ˆdataloaderï¼‰ã€‚ä½†åœ¨æˆ‘ä»¬å®šä¹‰è¿™äº›æ•°æ®åŠ è½½å™¨ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹ `tokenized_datasets` è¿›è¡Œä¸€äº›åå¤„ç†ï¼Œä»¥å¤„ç†ä¸€äº›è®­ç»ƒå™¨è‡ªåŠ¨ä¸ºæˆ‘ä»¬åšçš„äº‹æƒ…ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬éœ€è¦ï¼š\n",
        "\n",
        "1. ç§»é™¤æ¨¡å‹ä¸éœ€è¦çš„åˆ—ï¼ˆå¦‚ `sentence1` å’Œ `sentence2` åˆ—ï¼‰ã€‚\n",
        "2. å°† `label` åˆ—é‡å‘½åä¸º `labels`ï¼ˆå› ä¸ºæ¨¡å‹æœŸæœ›è¿™ä¸ªå‚æ•°è¢«å‘½åä¸º `labels`ï¼‰ã€‚\n",
        "3. è®¾ç½®æ•°æ®é›†çš„æ ¼å¼ï¼Œä»¥ä¾¿å®ƒä»¬è¿”å› PyTorch å¼ é‡ï¼Œè€Œä¸æ˜¯åˆ—è¡¨ã€‚"
      ],
      "metadata": {
        "id": "hpiGsl896MQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets[\"train\"].column_names"
      ],
      "metadata": {
        "id": "frEsP3Uw5UB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "DJQWYYRh6nO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader æ˜¯ PyTorch ä¸­ä¸€ä¸ªéå¸¸é‡è¦çš„ç±»ï¼Œå®ƒç”¨äºæ‰¹é‡åŠ è½½æ•°æ®å¹¶å°†æ•°æ®åˆ†æˆå°æ‰¹æ¬¡ï¼ˆbatchï¼‰ã€‚åœ¨è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å°†æ•°æ®é›†åˆ’åˆ†ä¸ºå¤šä¸ªå°æ‰¹æ¬¡ï¼Œæ¯æ¬¡ä»ä¸­è¯»å–ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚DataLoader ä½¿å¾—è¿™ä¸ªè¿‡ç¨‹å˜å¾—æ›´åŠ æ–¹ä¾¿å’Œé«˜æ•ˆã€‚"
      ],
      "metadata": {
        "id": "lsWWSx0_7hS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "collate_fn=data_collator è¿™ä¸ªå‚æ•°ç”¨äºæŒ‡å®šä¸€ä¸ªè‡ªå®šä¹‰çš„ collate functionï¼ˆåˆå¹¶å‡½æ•°ï¼‰æ¥å¤„ç†æ•°æ®åŠ è½½å™¨ï¼ˆDataLoaderï¼‰åœ¨æ¯ä¸ªæ‰¹æ¬¡å¤„ç†æ—¶çš„è¡Œä¸ºã€‚\n",
        "\n",
        "åœ¨ PyTorch ä¸­ï¼Œcollate_fn è´Ÿè´£å°†ä¸€ä¸ªæ‰¹æ¬¡çš„æ ·æœ¬ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡æ•°æ®ï¼ˆbatchï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒPyTorch çš„ DataLoader ä¼šå°†æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬æŒ‰æ‰¹æ¬¡åŠ è½½å¹¶è‡ªåŠ¨å°†å®ƒä»¬ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡ï¼Œé€šå¸¸æ˜¯é€šè¿‡ç®€å•çš„æ‹¼æ¥æ“ä½œã€‚ç„¶è€Œï¼ŒæŸäº›æƒ…å†µä¸‹ï¼Œå°¤å…¶æ˜¯å½“è¾“å…¥æ•°æ®çš„æ ¼å¼æˆ–å¤§å°ä¸ä¸€è‡´æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰å¦‚ä½•å°†è¿™äº›æ ·æœ¬åˆå¹¶ä¸ºä¸€ä¸ªæ‰¹æ¬¡ã€‚"
      ],
      "metadata": {
        "id": "MubehLyW7mmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "id": "RvjQgVwP8H8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ],
      "metadata": {
        "id": "RB2-hDKv8g80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add optimizer\n",
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "j7Eq31f-820j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ€åï¼Œé»˜è®¤ä½¿ç”¨çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ˜¯ä»æœ€å¤§å€¼ï¼ˆ5e-5ï¼‰åˆ° 0 çš„çº¿æ€§è¡°å‡ã€‚ä¸ºäº†æ­£ç¡®åœ°å®šä¹‰å®ƒï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“æˆ‘ä»¬å°†è¿›è¡Œçš„è®­ç»ƒæ­¥éª¤æ•°ï¼Œè¿™ä¸ªæ•°å€¼æ˜¯æˆ‘ä»¬æƒ³è¦è¿è¡Œçš„ epoch æ•°é‡ä¹˜ä»¥è®­ç»ƒæ‰¹æ¬¡çš„æ•°é‡ï¼ˆå³è®­ç»ƒæ•°æ®åŠ è½½å™¨çš„é•¿åº¦ï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ`Trainer` ä½¿ç”¨ 3 ä¸ª epochï¼Œæ‰€ä»¥æˆ‘ä»¬å°†æŒ‰ç…§è¿™ä¸ªè®¾ç½®ï¼š"
      ],
      "metadata": {
        "id": "qBmZ1ctJ9LDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "id": "VWMCEDvY9Lw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ®µä»£ç è®¡ç®—äº†è®­ç»ƒçš„æ€»æ­¥éª¤æ•°ï¼Œå¹¶ä¸ºè®­ç»ƒè®¾ç½®äº†ä¸€ä¸ª çº¿æ€§è¡°å‡ çš„å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ŒæŒ‡å®šå­¦ä¹ ç‡ä»åˆå§‹å€¼çº¿æ€§ä¸‹é™åˆ° 0ã€‚è¿™ä¸ªè°ƒåº¦å™¨å°†é€šè¿‡ optimizer æ¥æ§åˆ¶å­¦ä¹ ç‡çš„å˜åŒ–ï¼Œå¹¶ä¸”ä¸ä½¿ç”¨ warm-up æ­¥éª¤ã€‚"
      ],
      "metadata": {
        "id": "pVqJwFyj98RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "id": "gqPUd9xJ9-nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "SnK3jwUw-kyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ®µä»£ç ç”¨äºæ‰§è¡Œæ¨¡å‹çš„è®­ç»ƒå¾ªç¯ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾ç¤ºä¸€ä¸ªè¿›åº¦æ¡ã€‚ä¸‹é¢æ˜¯å¯¹ä»£ç çš„é€è¡Œè§£é‡Šï¼š\n",
        "\n",
        "### 1. `from tqdm.auto import tqdm`\n",
        "- è¿™è¡Œä»£ç ä» `tqdm` åº“å¯¼å…¥äº† `tqdm`ï¼Œå®ƒç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„è¿›åº¦æ¡ã€‚`tqdm.auto` ä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è¿›åº¦æ¡æ ¼å¼ï¼ˆä¾‹å¦‚ï¼ŒJupyter ç¬”è®°æœ¬ä¸­çš„è¿›åº¦æ¡ä¼šæœ‰æ‰€ä¸åŒï¼‰ã€‚\n",
        "\n",
        "### 2. `progress_bar = tqdm(range(num_training_steps))`\n",
        "- åˆ›å»ºä¸€ä¸ªè¿›åº¦æ¡å¯¹è±¡ `progress_bar`ï¼Œå®ƒçš„æ€»é•¿åº¦æ˜¯ `num_training_steps`ï¼ˆè®­ç»ƒçš„æ€»æ­¥éª¤æ•°ï¼‰ã€‚`range(num_training_steps)` ç”Ÿæˆä¸€ä¸ªä» 0 åˆ° `num_training_steps-1` çš„åºåˆ—ï¼Œè¿›åº¦æ¡å°†æ˜¾ç¤ºè®­ç»ƒçš„è¿›åº¦ã€‚\n",
        "\n",
        "### 3. `model.train()`\n",
        "- å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ã€‚æ¨¡å‹åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ä¼šå¯ç”¨æŸäº›ç‰¹æ€§ï¼Œä¾‹å¦‚ Dropout å’Œ BatchNormï¼Œå®ƒä»¬åœ¨è®­ç»ƒå’Œè¯„ä¼°é˜¶æ®µçš„è¡Œä¸ºä¸åŒã€‚\n",
        "\n",
        "### 4. `for epoch in range(num_epochs):`\n",
        "- è¿™ä¸ªå¾ªç¯éå†æŒ‡å®šæ•°é‡çš„è®­ç»ƒ epochï¼ˆè®­ç»ƒæ¬¡æ•°ï¼‰ã€‚åœ¨æ¯æ¬¡è¿­ä»£æ—¶ï¼Œæ•´ä¸ªè®­ç»ƒæ•°æ®é›†ä¼šè¢«ä½¿ç”¨ä¸€æ¬¡ã€‚\n",
        "\n",
        "### 5. `for batch in train_dataloader:`\n",
        "- éå†è®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼ˆ`train_dataloader`ï¼‰ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡ã€‚æ¯ä¸ªæ‰¹æ¬¡åŒ…å«è‹¥å¹²ä¸ªæ ·æœ¬ï¼Œæ•°æ®åŠ è½½å™¨ä¼šè‡ªåŠ¨å°†å®ƒä»¬åŠ è½½åˆ°å†…å­˜ä¸­ã€‚\n",
        "\n",
        "### 6. `batch = {k: v.to(device) for k, v in batch.items()}`\n",
        "- è¿™è¡Œä»£ç å°†æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼ˆ`batch`ï¼‰ä¸­çš„æ‰€æœ‰å¼ é‡ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¡ç®—è®¾å¤‡ï¼ˆå¦‚ GPU æˆ– CPUï¼‰ã€‚`device` æ˜¯æ¨¡å‹è¿è¡Œçš„è®¾å¤‡ï¼ˆå¯èƒ½æ˜¯ `\"cuda\"` æˆ– `\"cpu\"`ï¼‰ã€‚è¿™ç¡®ä¿äº†æ¨¡å‹å’Œæ•°æ®éƒ½åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šè¿›è¡Œè®¡ç®—ã€‚\n",
        "\n",
        "### 7. `outputs = model(**batch)`\n",
        "- å°†æ‰¹æ¬¡ä¸­çš„æ•°æ®ä¼ é€’ç»™æ¨¡å‹è¿›è¡Œå‰å‘è®¡ç®—ã€‚`**batch` ä½¿ç”¨ Python çš„è§£åŒ…è¯­æ³•ï¼Œå°†æ‰¹æ¬¡å­—å…¸ä¸­çš„é”®å€¼å¯¹ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œ`input_ids` å’Œ `attention_mask`ï¼‰ã€‚\n",
        "- `outputs` æ˜¯æ¨¡å‹çš„è¾“å‡ºï¼Œé€šå¸¸åŒ…æ‹¬æŸå¤±å€¼å’Œå…¶ä»–ç›¸å…³æ•°æ®ï¼ˆä¾‹å¦‚ logitsï¼‰ã€‚\n",
        "\n",
        "### 8. `loss = outputs.loss`\n",
        "- ä»æ¨¡å‹çš„è¾“å‡ºä¸­æå–æŸå¤±å€¼ï¼ˆ`loss`ï¼‰ã€‚åœ¨ PyTorch ä¸­ï¼ŒæŸå¤±æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­ç”¨äºä¼˜åŒ–çš„ç›®æ ‡ã€‚\n",
        "\n",
        "### 9. `loss.backward()`\n",
        "- æ‰§è¡Œåå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ï¼Œè®¡ç®—æ¢¯åº¦ã€‚å®ƒå°†æ ¹æ®æŸå¤±å€¼æ›´æ–°æ¨¡å‹ä¸­å„ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚\n",
        "\n",
        "### 10. `optimizer.step()`\n",
        "- æ‰§è¡Œä¼˜åŒ–å™¨çš„ `step()` æ“ä½œï¼Œæ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚ä¼˜åŒ–å™¨ä½¿ç”¨åå‘ä¼ æ’­è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦æ¥è°ƒæ•´å‚æ•°ï¼Œä»¥å‡å°‘æŸå¤±ã€‚\n",
        "\n",
        "### 11. `lr_scheduler.step()`\n",
        "- è°ƒæ•´å­¦ä¹ ç‡ï¼ˆå¦‚æœä½¿ç”¨äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼‰ã€‚å®ƒä¼šæ ¹æ®è®¾å®šçš„è°ƒåº¦ç­–ç•¥ï¼ˆä¾‹å¦‚çº¿æ€§è¡°å‡ï¼‰æ›´æ–°å­¦ä¹ ç‡ã€‚\n",
        "\n",
        "### 12. `optimizer.zero_grad()`\n",
        "- æ¸…é™¤ä¹‹å‰è®¡ç®—çš„æ¢¯åº¦ã€‚PyTorch ä¸­çš„æ¢¯åº¦æ˜¯ç´¯ç§¯çš„ï¼Œå› æ­¤æ¯æ¬¡æ¢¯åº¦è®¡ç®—ä¹‹å‰éœ€è¦å°†æ¢¯åº¦å½’é›¶ï¼Œä»¥é˜²æ­¢æ¢¯åº¦ç´¯ç§¯é”™è¯¯ã€‚\n",
        "\n",
        "### 13. `progress_bar.update(1)`\n",
        "- æ›´æ–°è¿›åº¦æ¡ï¼Œæ¯å®Œæˆä¸€æ­¥è®­ç»ƒï¼ˆå³ä¸€ä¸ªæ‰¹æ¬¡ï¼‰ï¼Œè¿›åº¦æ¡å°±å‰è¿›ä¸€æ­¥ã€‚è¿™ä¼šå®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦ï¼Œå¸®åŠ©ç›‘æ§è®­ç»ƒè¿‡ç¨‹ã€‚\n",
        "\n",
        "### æ€»ç»“ï¼š\n",
        "è¿™æ®µä»£ç å®ç°äº†ä¸€ä¸ªæ ‡å‡†çš„è®­ç»ƒå¾ªç¯ï¼Œå…¶ä¸­åŒ…æ‹¬ï¼š\n",
        "1. æ•°æ®çš„å‰å‘ä¼ é€’ã€‚\n",
        "2. æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­ã€‚\n",
        "3. å‚æ•°æ›´æ–°å’Œå­¦ä¹ ç‡è°ƒåº¦ã€‚\n",
        "4. ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºè®­ç»ƒè¿›åº¦ã€‚\n",
        "   \n",
        "æ¯å®Œæˆä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®å¤„ç†ï¼Œè¿›åº¦æ¡å°±ä¼šæ›´æ–°ä¸€æ¬¡ï¼Œä»è€Œå®æ—¶æ˜¾ç¤ºè®­ç»ƒçš„è¿›åº¦ã€‚"
      ],
      "metadata": {
        "id": "wxoEocOx_SzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation loop\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "metadata": {
        "id": "wUaxh-fw_Tih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
